from itertools import combinations
from typing import Callable, Union

import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
from matplotlib import colors
from matplotlib.axes import Axes
from mpl_toolkits import axes_grid1
from sklearn.decomposition import PCA
from torch import Tensor

from .eval import Metrics
from .replay import iterate
from .utils import chunk, flatten, get_closest_item

# div_cmap = sns.diverging_palette(0, 255, sep=5, as_cmap=True)
# div_cmap = sns.diverging_palette(20, 220, as_cmap=True)
div_cmap = sns.diverging_palette(-10, 250, as_cmap=True)
# seq_cmap = sns.light_palette((255, 75, 50), input="husl", as_cmap=True)
# seq_cmap = sns.light_palette((220, 80, 50), input="husl", as_cmap=True)
# seq_cmap = sns.light_palette((250, 80, 50), input="husl", as_cmap=True)
seq_cmap = sns.light_palette((250, 80, 50), input="husl", as_cmap=True)
# seq_cmap = sns.cubehelix_palette(10, rot=-0.25, light=0.7, as_cmap=True)

colormap = {
    "Robin": "#e57373",
    "Sunfish": "#FDD500",
    "Oak": "#81c784",
    "Pine": "#2e7d32",
    "Canary": "#FFF402",
    "Daisy": "#FEA401",
    "Salmon": "#ff4081",
    "Rose": "#dd2c00",
}


def add_colorbar(image, aspect=20, pad_fraction=0.5, **kwargs):
    """
    Add a vertical color bar on the right side of a plotted image.
    S/o to: https://nbviewer.jupyter.org/github/mgeier/python-audio/blob/master/plotting/matplotlib-colorbar.ipynb
    """
    ax = image.axes
    fig = ax.figure

    divider = axes_grid1.make_axes_locatable(ax)
    size = axes_grid1.axes_size.AxesY(image.axes, aspect=1.0 / aspect)
    pad = axes_grid1.axes_size.Fraction(pad_fraction, size)

    cax = divider.append_axes("right", size=size, pad=pad, **kwargs)
    cbar = fig.colorbar(image, cax=cax)
    # cbar.set_ticks([-1, -0.5, 0, 0.5, 1])
    # cbar.ax.set_yticklabels([-1, 1])
    return cbar


def with_ax(f: Callable) -> Callable:
    """
    Decorator that handles axes passing or creation.
    Makes functions return their ax whenever they would return `None`.
    """

    def wrapper(*args, **kwargs):
        if "ax" not in kwargs or kwargs["ax"] is None:
            # ax = plt.gca()
            fig, ax = plt.subplots()
            kwargs["ax"] = ax
        else:
            ax = kwargs["ax"]

        result = f(*args, **kwargs)
        return ax if result is None else result

    return wrapper


@with_ax
def plot_singular_values(data_df: pd.DataFrame, test_df: pd.DataFrame, ax: Axes = None):
    data = []
    index = data_df.columns if set(data_df.columns).issubset(test_df.columns) else data_df.index

    u, s, vT = np.linalg.svd(data_df.transpose(), full_matrices=False)
    # u_inv, vT_inv = np.linalg.inv(u), np.linalg.inv(vT)

    for epoch in test_df["epoch"].unique():
        df = test_df[test_df["epoch"] == epoch][index].transpose()
        u, s, vT = np.linalg.svd(df.transpose(), full_matrices=False)
        data.append(s)
        # A_t = u_inv @ df @ vT_inv
        # data.append(A_t)

    data = np.array(data)

    for mode in range(0, len(data[0])):
        values = data[:, mode]
        ax.plot(values, label=f"Mode {mode + 1}")

    ax.set_title("Singular values of SVD modes")
    ax.legend(loc="upper right", prop={"size": 7})
    plt.tight_layout()


@with_ax
def plot_individual_loss(df: pd.DataFrame, ax: Axes = None):
    for index in df.index.unique():
        data = df[df.index == index].sort_values("epoch")["loss"].to_list()
        ax.plot(data, label=index)
        ax.set_title("Loss per item")

    ax.legend(fontsize=7)


@with_ax
def plot_individual_accuracy(df: pd.DataFrame, ax: Axes = None):
    for index in df.index.unique():
        data = df[df.index == index].sort_values("epoch")["accuracy"].to_list()
        ax.plot(data, label=index)
        ax.set_title("Accuracy per item")

    ax.legend(fontsize=7)


def plot_metrics(metrics: Union[Metrics, list[Metrics]]):
    """
    Plot the metrics generated by `train_model`.
    """
    fig = plt.figure(figsize=(11, 5))
    grid = fig.add_gridspec(nrows=2, ncols=3, width_ratios=[1, 0.1, 1])

    ax1 = fig.add_subplot(grid[0, :])
    ax2 = fig.add_subplot(grid[1, 0])
    ax3 = fig.add_subplot(grid[1, 2])

    if isinstance(metrics, (list, tuple)):
        lens = [m.predictions["epoch"].nunique() for m in metrics]
        line_locs = [sum(lens[: i + 1]) for i in range(len(lens) - 1)]

        m = metrics[0]
        for _m in metrics[1:]:
            m = m.join(_m)
        metrics = m

        for ax in [ax1, ax2, ax3]:
            for x in line_locs:
                ax.axvline(x=x, color="xkcd:grey", linestyle="--", alpha=0.75)

            locs = line_locs
            if len(locs) % 2 != 0:
                locs.append(m.predictions["epoch"].max())

            locs = [[*x, x[-1]] for x in chunk(locs, 2)]
            where = [[True, True, False] for x in locs]

            ax.fill_between(
                [*flatten(locs)],
                0,
                1,
                where=[*flatten(where)],
                alpha=0.1,
                color="xkcd:light purple",
                transform=ax.get_xaxis_transform(),
            )

    ax1.plot(metrics.losses["train"], label="train")
    ax1.plot(metrics.losses["test"], label="test")
    ax1.set_title("Loss")
    ax1.legend()

    plot_individual_accuracy(metrics.predictions, ax=ax2)
    plot_individual_loss(metrics.predictions, ax=ax3)

    with plt.style.context({"legend.frameon": True}):
        handles, labels = ax2.get_legend_handles_labels()

        for ax in [ax2, ax3]:
            ax.get_legend().remove()

        legend_ax = fig.add_subplot(grid[1, 1])
        legend_ax.legend(handles, labels, borderaxespad=0.0, loc="upper right", prop={"size": 9})
        legend_ax.axis("off")
    # plot_singular_values(dataloader.dataset.df, metrics, ax=axes[1, 1])

    fig.tight_layout()


@with_ax
def plot_tensor(
    data: Union[Tensor, pd.DataFrame, np.ndarray, list], colorbar=True, ax: Axes = None, **kwargs
):
    """
    Plot a tensor of <= 2 dimensions.
    """
    if not isinstance(data, Tensor):
        tensor = torch.tensor(data.values if isinstance(data, pd.DataFrame) else data)
    else:
        tensor = data
        if tensor.requires_grad == True:
            tensor = tensor.clone().detach()

    tensor = tensor.squeeze()

    if len(tensor.shape) > 2:
        raise Exception(f"Can't show a {len(tensor.shape)}-dimensional tensor!")

    tensor = tensor.view([tensor.shape[0], -1])

    min_value = torch.min(tensor).item()
    max_value = torch.max(tensor).item()
    mode = "diverging" if min_value < 0 else "sequential"

    if mode == "diverging":
        absmax = max(abs(max_value), abs(min_value))
        mesh_kwargs = {
            "cmap": div_cmap,
            "vmax": absmax,
            "vmin": -1 * absmax,
            **kwargs,
        }
    if mode == "sequential":
        mesh_kwargs = {
            "cmap": seq_cmap,
            "vmax": max_value,
            "vmin": min_value,
            **kwargs,
        }

    with plt.style.context(
        {
            "ytick.major.size": 3.5,
            "ytick.major.width": 0.6,
            "ytick.minor.size": 2,
            "axes.linewidth": 0.6,
            "axes.edgecolor": "black",
        }
    ):
        ax.set_aspect("equal")
        ax.invert_yaxis()
        ax.set_xticks(np.arange(0, tensor.shape[1], 1))
        ax.set_yticks(np.arange(0, tensor.shape[0], 1))

        for axis in ["top", "bottom", "left", "right"]:
            spine = ax.spines[axis]
            spine.set_visible(True)
            spine.set_linewidth(0.6)
            spine.set_color("black")

        if isinstance(data, (pd.Series, pd.DataFrame)):
            if isinstance(data, pd.DataFrame):
                x_all_numeric = all(isinstance(x, int) for x in data.columns)
                xticklabels = [] if len(data.columns) <= 1 and x_all_numeric else data.columns
                ax.set_xticklabels(xticklabels, rotation=-45 if not x_all_numeric else 0)
            else:
                ax.set_xticklabels(list(range(tensor.shape[1])) if tensor.shape[1] > 1 else [])

            y_all_numeric = all(isinstance(x, int) for x in data.index)
            yticklabels = [] if len(data.index) <= 1 and y_all_numeric else data.index
            ax.set_yticklabels(yticklabels)
        else:
            ax.set_xticklabels(list(range(tensor.shape[1])) if tensor.shape[1] > 1 else [])
            ax.set_yticklabels(list(range(tensor.shape[0])) if tensor.shape[0] > 1 else [])

        image = ax.imshow(
            tensor.numpy(),
            **mesh_kwargs,
            # facecolor="white",
            # edgecolors="black",
            # linewidth=0.2 if mpl.rcParams["savefig.format"] == "eps" else 0,
            interpolation="nearest" if mpl.rcParams["savefig.format"] == "pdf" else "none",
        )
        if colorbar is True:
            add_colorbar(image)

        ax.tick_params(axis="both", which="both", top=False, bottom=False, left=False, right=False)
        plt.tight_layout()


def plot_SVD(df: pd.DataFrame):
    """
    Plot the singular value decomposition of a dataframe.
    """
    df = df.transpose()
    u, s, vT = np.linalg.svd(df, full_matrices=False)

    first_letters = list(map(lambda x: x[0], df.index))
    modes = list(map(lambda x: x + 1, range(len(df.columns))))

    with plt.style.context(
        {
            "axes.spines.top": True,
            "axes.spines.right": True,
            "axes.spines.bottom": True,
            "axes.spines.left": True,
        }
    ):
        fig = plt.figure(figsize=(10.5, 3))
        # fig.suptitle("Singular value decomposition", fontsize=16)
        axes = fig.add_gridspec(nrows=1, ncols=4).subplots()

        plot_tensor(df, ax=axes[0])
        axes[0].set_xticklabels(df.columns, rotation=-45)
        axes[0].set_yticklabels(df.index)
        axes[0].set_xlabel("Items")
        axes[0].set_ylabel("Attributes")
        axes[0].set_title("$\Sigma^{yx}$")

        plot_tensor(u, ax=axes[1])
        axes[1].set_yticks(np.arange(0.5, len(first_letters), 1))
        axes[1].set_xticklabels(modes)
        axes[1].set_yticklabels(first_letters)
        axes[1].set_xlabel("Modes")
        axes[1].set_ylabel("Attributes")
        axes[1].set_title("$U$")

        plot_tensor(np.diag(s), ax=axes[2])
        axes[2].set_xticklabels(modes)
        axes[2].set_yticklabels(modes)
        axes[2].set_xlabel("Modes")
        axes[2].set_ylabel("Modes")
        axes[2].set_title("$S$")

        plot_tensor(vT, ax=axes[3])
        axes[3].set_xticklabels(df.columns, rotation=-45)
        axes[3].set_yticklabels(modes)
        axes[3].set_xlabel("Items")
        axes[3].set_ylabel("Modes")
        axes[3].set_title("$V^{T}$")

        for ax in axes:
            ax.tick_params(axis="both", which="both", length=0)

        fig.tight_layout()

    # df = df.transpose()
    # u, s, vT = np.linalg.svd(df, full_matrices=False)

    # first_letters = list(map(lambda x: x[0], df.index))
    # modes = list(map(lambda x: x + 1, range(len(df.columns))))

    # with plt.style.context(
    #     [
    #         {
    #             "axes.spines.top": True,
    #             "axes.spines.right": True,
    #             "axes.spines.bottom": True,
    #             "axes.spines.left": True,
    #         }
    #     ]
    # ):
    #     fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 4))

    # # fig.suptitle("Singular value decomposition", fontsize=16)
    # plt.tight_layout()

    # plot_tensor(df, ax=axes[0])
    # axes[0].set_xticklabels(df.columns, rotation=-45)
    # axes[0].set_yticklabels(df.index)
    # axes[0].set_xlabel("Items")
    # axes[0].set_ylabel("Attributes")
    # axes[0].set_title("$\Sigma^{yx}$")

    # plot_tensor(u, ax=axes[1])
    # axes[1].set_yticks(np.arange(0.5, len(first_letters), 1))
    # axes[1].set_xticklabels(modes)
    # axes[1].set_yticklabels(first_letters)
    # axes[1].set_xlabel("Modes")
    # axes[1].set_ylabel("Attributes")
    # axes[1].set_title("$U$")

    # plot_tensor(np.diag(s), ax=axes[2])
    # axes[2].set_xticklabels(modes)
    # axes[2].set_yticklabels(modes)
    # axes[2].set_xlabel("Modes")
    # axes[2].set_ylabel("Modes")
    # axes[2].set_title("$S$")

    # plot_tensor(vT, ax=axes[3])
    # axes[3].set_xticklabels(df.columns, rotation=-45)
    # axes[3].set_yticklabels(modes)
    # axes[3].set_xlabel("Items")
    # axes[3].set_ylabel("Modes")
    # axes[3].set_title("$V^{T}$")

    # for ax in axes:
    #     ax.tick_params(axis="both", which="both", length=0)
    #     # ax.grid(axis="both", which="both", linewidth=0)


@with_ax
def plot_parameters(metrics, ax: Axes = None):
    if isinstance(metrics, (list, tuple)):
        m = metrics[0]
        for _m in metrics[1:]:
            m = m.join(_m)
        metrics = m

    for name, layer in metrics.parameters.items():
        diff = np.diff(torch.stack(layer), axis=0)
        diff = np.abs(diff)
        total_diff = np.sum(diff, axis=tuple(range(1, len(diff.shape))))
        ax.plot(total_diff, label=name)

    ax.set_title("Total absolute parameter change per epoch")
    ax.set_ylabel("$\Sigma |\Delta W|$")
    ax.set_xlabel("Epoch")
    ax.legend()


@torch.no_grad()
def plot_grid(model, dataloader):
    model.eval()

    attractors = torch.vstack([model.encoder(x["y"]) for x in dataloader.dataset])

    if attractors.shape[1] > 2:
        pca = PCA(n_components=2)
        attractors = torch.tensor(pca.fit_transform(attractors))
        print(pca.explained_variance_ratio_)

    xs = attractors[:, 0]
    ys = attractors[:, 1]

    xmax, xmin = xs.max(), xs.min()
    ymax, ymin = ys.max(), ys.min()
    xrange, yrange = abs(xmax - xmin), abs(ymax - ymin)
    xpad, ypad = xrange / 2, yrange / 2

    resolution = 100
    x = np.linspace(xmin - xpad, xmax + xpad, num=resolution)
    y = np.linspace(ymin - ypad, ymax + ypad, num=resolution)
    xg, yg = np.meshgrid(x, y)

    z = []
    zx, zy = [], []
    for x, y in zip(xg.ravel(), yg.ravel()):
        activ = torch.tensor([x, y], dtype=torch.float32)

        if "pca" in locals():
            activ = torch.tensor(pca.inverse_transform(activ), dtype=torch.float32)

        y_pred = model.decoder(activ)
        item = get_closest_item(dataloader.dataset.df, y_pred, metric="euclidean")
        z.append(item[0])

        _, activations = iterate(model, initial_state=y_pred, runs=1, steps=10)
        final_activ = activations.squeeze()[-1].numpy()
        diff = np.subtract(final_activ, activ)

        if "pca" in locals():
            diff = pca.transform(diff.unsqueeze(dim=0))
            diff = diff.squeeze()

        zx.append(diff[0])
        zy.append(diff[1])

    cmap = colors.ListedColormap([*colormap.values()])
    classes = np.array([list(colormap.keys()).index(x) for x in z]).reshape(xg.shape)
    plt.pcolormesh(xg, yg, classes, cmap=cmap, alpha=0.5, vmin=0, vmax=cmap.N, shading="nearest")

    i = 4
    zx = np.array(zx).reshape(xg.shape)
    zy = np.array(zy).reshape(yg.shape)
    plt.scatter(xg[::i, ::i], yg[::i, ::i], c=classes[::i, ::i], cmap=cmap, alpha=0.75, s=2)
    plt.quiver(xg[::i, ::i], yg[::i, ::i], zx[::i, ::i], zy[::i, ::i], alpha=0.6, units="xy")

    for i, item in enumerate(attractors):
        plt.scatter(
            item[0],
            item[1],
            color=colormap[dataloader.dataset.df.index[i]],
            edgecolors="black",
            marker="*",
            alpha=0.75,
            s=100,
        )

    if "pca" in locals():
        plt.xlabel("PC1")
        plt.ylabel("PC2")
        print("PCA attractors", attractors)


@torch.no_grad()
@plt.style.context(
    {
        "axes.xmargin": 0.06,
        "axes.ymargin": 0.06,
        "axes.spines.top": True,
        "axes.spines.right": True,
        # "figure.figsize": (12, 3.54),
    }
)
def plot_better_grid(model, dataloader, n_components=2, xlim=[-2, 6], ylim=[-2, 6]):
    model.eval()
    palette = {
        "Oak": "#B0E65A",
        "Pine": "#75993C",
        "Daisy": "#FEB756",
        "Rose": "#E6634E",
        "Salmon": "#9194E3",
        "Sunfish": "#8BCBD9",
        "Canary": "#FFD92F",
        "Robin": "#FF8C9A",
    }

    attractors = torch.vstack([model.encoder(x["y"]) for x in dataloader.dataset])
    if attractors.shape[1] > 2:
        pca = PCA(n_components=n_components)
        attractors = torch.tensor(pca.fit_transform(attractors))
        print(pca.explained_variance_ratio_)

    stuff = []
    for dim_a, dim_b in combinations(range(n_components), 2):
        aa = attractors[:, dim_a]
        bb = attractors[:, dim_b]
        center = [aa.mean(), bb.mean()]
        length = max(
            abs(aa.max() - aa.min()),
            abs(bb.max() - bb.min()),
        )

        resolution = 100
        arrow_stride = 4 * 2
        sl = slice(4, -4, arrow_stride)
        _a = np.linspace(xlim[0], xlim[1], num=resolution + 4 + 1)
        _b = np.linspace(ylim[0], ylim[1], num=resolution + 4 + 1)
        # arrow_stride = 4
        # sl = slice(1, -1, arrow_stride)
        # _a = np.linspace(xlim[0], xlim[1], num=resolution + 1)
        # _b = np.linspace(ylim[0], ylim[1], num=resolution + 1)
        # _a = np.linspace(center[0] - length/1.5, center[0] + length/1.5, num=resolution + 1)
        # _b = np.linspace(center[1] - length/1.5, center[1] + length/1.5, num=resolution + 1)
        ag, bg = np.meshgrid(_a, _b)

        z, zx, zy = [], [], []
        for a, b in zip(ag.ravel(), bg.ravel()):
            activ = torch.zeros(n_components, dtype=torch.float32)
            activ[dim_a] = a
            activ[dim_b] = b

            if "pca" in locals():
                activ = torch.tensor(pca.inverse_transform(activ), dtype=torch.float32)

            y_pred = model.decoder(activ)
            item = get_closest_item(dataloader.dataset.df, y_pred, metric="euclidean")
            z.append(item[0])

            _, activations = iterate(model, initial_state=y_pred, runs=1, steps=10)
            final_activ = activations.squeeze()[-1].numpy()
            diff = np.subtract(final_activ, activ)

            if "pca" in locals():
                diff = pca.transform(diff.unsqueeze(dim=0))
                diff = diff.squeeze()

            zx.append(diff[0])
            zy.append(diff[1])

        classes = np.array([list(palette.keys()).index(x) for x in z]).reshape(ag.shape)
        zx, zy = np.array(zx).reshape(ag.shape), np.array(zy).reshape(bg.shape)
        things = [ag, bg, zx, zy, classes, sl, attractors[:, (dim_a, dim_b)]]
        stuff.append(things)

    cmap = colors.ListedColormap([*palette.values()])
    norm = colors.BoundaryNorm(np.arange(-0.5, len(palette)), len(palette))

    if not "pca" in locals():
        pca = None

    # return stuff, cmap, palette, pca

    ag, bg, zx, zy, classes, sl, attractors = stuff[0]

    plt.scatter(ag, bg, s=11, c=classes, cmap=cmap, norm=norm, alpha=0.3, edgecolors="none")

    plt.quiver(
        ag[sl, sl],
        bg[sl, sl],
        zx[sl, sl],
        zy[sl, sl],
        units="xy",
        alpha=0.6,
    )

    for i, item in enumerate(attractors):
        plt.scatter(
            item[0],
            item[1],
            color=palette[dataloader.dataset.df.index[i]],
            edgecolors="black",
            marker="*",
            alpha=0.75,
            s=140,
        )

    # plt.tick_params(axis="both",)
    plt.xlabel("First hidden dimension")
    plt.ylabel("Second hidden dimension")
    plt.tight_layout()
