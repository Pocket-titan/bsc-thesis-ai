{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%run ../_preamble.ipynb\n",
    "from _work.src.modules import AutoEncoder, train_model, plot_metrics, plot_tensor\n",
    "from _work.src.modules.utils import save_metrics, load_metrics\n",
    "from _work.src.data import small_dataloader as dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from ray import tune\n",
    "import ray"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jelmar/Github/deep/.venv/lib/python3.9/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ray.shutdown()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "ray.init(local_mode=True, num_cpus=1, num_gpus=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-27 15:11:42,783\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.26.170.179',\n",
       " 'raylet_ip_address': '172.26.170.179',\n",
       " 'redis_address': '172.26.170.179:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-07-27_15-11-41_387224_2005/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-07-27_15-11-41_387224_2005/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-07-27_15-11-41_387224_2005',\n",
       " 'metrics_export_port': 60329,\n",
       " 'node_id': '1300006a25040a25e3cdf7875a80f2f02e5f782335475577089c51ba'}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def training_function(config):\n",
    "    model = AutoEncoder(sizes=config['sizes'], batch_norm=config['batch_norm'], dropout=config['dropout'])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "    loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def callback(epoch, loss, predictions):\n",
    "        accuracy = predictions[\"accuracy\"].mean()\n",
    "        tune.report(mean_loss=loss)\n",
    "\n",
    "    metrics = train_model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        dataloader,\n",
    "        epochs=config['epochs'],\n",
    "        noise_mean=config['noise_mean'],\n",
    "        noise_stdev=config['noise_stdev'],\n",
    "        noise_multiplier=config['noise_multiplier'],\n",
    "        l1_lambda=config['l1_lambda'],\n",
    "        callback=callback,\n",
    "    )\n",
    "\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        'sizes': [dataloader.dataset.NUM_ATTRIBUTES, 2],\n",
    "        'batch_norm': tune.grid_search([True, False]),\n",
    "        'dropout': 0,\n",
    "        'lr': tune.grid_search([1e-2, 1e-3]),\n",
    "        'epochs': 200,\n",
    "        'noise_mean': 0,\n",
    "        'noise_stdev': 1,\n",
    "        'noise_multiplier': 0.1,\n",
    "        'l1_lambda': 0,\n",
    "    },\n",
    "    resources_per_trial={'gpu': 1},\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-27 15:11:50,116\tWARNING tune.py:494 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training model:   0%|\u001b[38;2;89;177;166m          \u001b[0m| 0/200 [00:00<?, ?epochs/s, accuracy=0.444, loss=22.4]"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "== Status ==<br>Memory usage on this node: 2.7/3.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/1 CPUs, 0/1 GPUs, 0.0/1.01 GiB heap, 0.0/0.51 GiB objects<br>Result logdir: /home/jelmar/ray_results/training_function_2021-07-27_15-11-50<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc  </th><th>batch_norm  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_34360_00000</td><td>RUNNING </td><td>     </td><td>True        </td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>training_function_34360_00001</td><td>PENDING </td><td>     </td><td>False       </td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>training_function_34360_00002</td><td>PENDING </td><td>     </td><td>True        </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "<tr><td>training_function_34360_00003</td><td>PENDING </td><td>     </td><td>False       </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-27 15:11:50,328\tWARNING session.py:51 -- A Tune session already exists in the current process. If you are using ray.init(local_mode=True), you must set ray.init(..., num_cpus=1, num_gpus=1) to limit available concurrency.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-27 15:14:35,635\tWARNING tune.py:506 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('.venv')"
  },
  "interpreter": {
   "hash": "5351f8576bcdb8e76d0a73356a50039c200b583d3e5a9c0de4f0e36f9849983f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}